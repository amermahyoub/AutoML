{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+Q73d0QRwrUxVZN8Y90nP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amermahyoub/AutoML/blob/main/AutoML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90qMZb528kpK"
      },
      "source": [
        "# !pip install streamlit -q\n",
        "\n",
        "import streamlit as st\n",
        "import base64\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_diabetes"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OP4V21-oHhSj",
        "outputId": "18fb8996-6542-4c0f-99f3-fc21e2ef49a5"
      },
      "source": [
        "import ipykernel\n",
        "ipykernel.__version__"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'5.1.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fsuj8x3--dV"
      },
      "source": [
        "# !pip install streamlit -q\n",
        "\n",
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip -qq ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# get_ipython().system_raw('./ngrok http 8501 &')\n",
        "# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "# !streamlit hello"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPwUMoNI-Vtt"
      },
      "source": [
        "# !pip uninstall ipykernel\n",
        "# !pip install ipykernel==5.1.2\n",
        "# !pip install pydeck\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk8-5j3N_7H3"
      },
      "source": [
        "# Page layout\n",
        "\n",
        "st.set_page_config(page_title='The Machine Learning Hyperparameter Optimization App',\n",
        "                   layout='wide', page_icon='random')\n",
        "\n",
        "st.write(\"\"\"\n",
        "# The Machine Learning Hyperparameter Optimization App\n",
        "**(Regression Edition)**\n",
        "In this implementation, the *RandomForestRegressor()* function is used in this app for build a regression model using the **Random Forest** algorithm.\n",
        "\"\"\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqsih-QtA5vY",
        "outputId": "e4f85ff6-6227-4013-ee85-99e94cc7649f"
      },
      "source": [
        "# Sidebar - Collects user input features into dataframe\n",
        "\n",
        "st.sidebar.header('Upload your CSV data')\n",
        "uploaded_file = st.sidebar.file_uploader('Upload your input CSV file', type='csv')\n",
        "st.sidebar.markdown(\"\"\"\n",
        "[Example CSV input file](https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv)\n",
        "\"\"\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator(_root_container=1, _provided_cursor=None, _parent=DeltaGenerator(_root_container=0, _provided_cursor=None, _parent=None, _block_type=None, _form_data=None), _block_type=None, _form_data=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwQWgBoLB2zt"
      },
      "source": [
        "# Sidebar - Specify parameter settings\n",
        "\n",
        "st.sidebar.header('Set Parameters')\n",
        "spit_size = st.sidebar.slider('Data split ratior (% for Training set)', \n",
        "                              min_value=10, max_value=90, value=80, step=5)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjFEugMKC5yg"
      },
      "source": [
        "st.subheader('Learning Parameters')\n",
        "parameter_n_estimator = st.sidebar.slider('Number of estimators (n_estimators)', 0, 500)\n",
        "parameter_n_estimator_step = st.sidebar.number_input('Step size for n_estomators', 10)\n",
        "st.sidebar.write('---')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDAWnGJrD29G"
      },
      "source": [
        "parameter_max_features = st.sidebar.slider('Max features (max_features)', 1, 50, (1,3), 1)\n",
        "st.sidebar.number_input('Step size for max_features', 1)\n",
        "st.sidebar.write('---')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQv9faBUElL3"
      },
      "source": [
        "parameter_min_samples_split = st.sidebar.slider('Minimum number of samples required to split an internal node (min_samples_split)'\n",
        "                                                , 1, 10, 2, 1)\n",
        "parameter_min_samples_leaf = st.sidebar.slider('Minimum number of samples required to be at a leaf node (min_samples_leaf)'\n",
        "                                                , 1, 10, 2, 1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHZDgXB3E6nn"
      },
      "source": [
        "st.sidebar.subheader('General Parameters')\n",
        "parameter_random_state = st.sidebar.slider('Seed number (random_state)', 0, 1000, 42, 1)\n",
        "parameter_criterion = st.sidebar.select_slider('Performance measure (criterion)', options=['mse', 'mae'])\n",
        "parameter_bootstrap = st.sidebar.select_slider('Bootstrap samples when building trees (bootstrap)', options=[True, False])\n",
        "parameter_oob_score = st.sidebar.select_slider('Whether to use out-of-bag samples to estimate the R^2 on unseen data (oob_score)', options=[False, True])\n",
        "parameter_n_jobs = st.sidebar.select_slider('Number of jobs to run in parallel (n_jobs)', options=[1, -1])\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-csJHCkHv0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adf8425-81a8-41d9-cb1b-6cac37158327"
      },
      "source": [
        "n_estimators_range = np.arange(parameter_n_estimator[0], parameter_n_estimator[1]+parameter_n_estimator_step, parameter_n_estimator_step)\n",
        "max_features_range = np.arange(parameter_max_features[0], parameter_max_features[1]+1, 1)\n",
        "param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puEYxMHywgg6"
      },
      "source": [
        "# Displays the dataset\n",
        "st.subheader('Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SvBuQFCwqZ8"
      },
      "source": [
        "# Model building\n",
        "\n",
        "def file_download(df):\n",
        "  csv = df.to_csv(index=False)\n",
        "  b64 = base64.b64encode(csv,encode()).decode() # strings <-> bytes conversions\n",
        "  href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"model_performance.csv\">Download CSV File</a>'\n",
        "  return href\n",
        "\n",
        "def build_model(df):\n",
        "  x = df.loc[:,:-1] # Using all column except for the last column as X\n",
        "  y = df.loc[:,-1] # Selecting the last column as Y\n",
        "\n",
        "  st.markdown('A model is being built to predict the following **Y** variable:')\n",
        "  st.info(y.name)\n",
        "\n",
        "  # Data splitting\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(y, x, test_size=split_size)\n",
        "\n",
        "  # Defining our Random Forest model\n",
        "  rf = RandomForestRegressor(n_estimators=parameter_n_estimators,\n",
        "        random_state=parameter_random_state,\n",
        "        max_features=parameter_max_features,\n",
        "        criterion=parameter_criterion,\n",
        "        min_samples_split=parameter_min_samples_split,\n",
        "        min_samples_leaf=parameter_min_samples_leaf,\n",
        "        bootstrap=parameter_bootstrap,\n",
        "        oob_score=parameter_oob_score,\n",
        "        n_jobs=parameter_n_jobs)\n",
        "  \n",
        "  grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
        "  grid_search.fit(X_train, Y_train)\n",
        "\n",
        "  Y_pred_test = grid.predict(X_test)\n",
        "    st.write('Coefficient of determination ($R^2$):')\n",
        "    st.info( r2_score(Y_test, Y_pred_test) )\n",
        "\n",
        "    st.write('Error (MSE or MAE):')\n",
        "    st.info( mean_squared_error(Y_test, Y_pred_test) )\n",
        "\n",
        "    st.write(\"The best parameters are %s with a score of %0.2f\"\n",
        "      % (grid.best_params_, grid.best_score_))\n",
        "\n",
        "    st.subheader('Model Parameters')\n",
        "    st.write(grid.get_params())\n",
        "\n",
        "    #-----Process grid data-----#\n",
        "    grid_results = pd.concat([pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"R2\"])],axis=1)\n",
        "    # Segment data into groups based on the 2 hyperparameters\n",
        "    grid_contour = grid_results.groupby(['max_features','n_estimators']).mean()\n",
        "    # Pivoting the data\n",
        "    grid_reset = grid_contour.reset_index()\n",
        "    grid_reset.columns = ['max_features', 'n_estimators', 'R2']\n",
        "    grid_pivot = grid_reset.pivot('max_features', 'n_estimators')\n",
        "    x = grid_pivot.columns.levels[1].values\n",
        "    y = grid_pivot.index.values\n",
        "    z = grid_pivot.values\n",
        "\n",
        "    #-----Plot-----#\n",
        "    layout = go.Layout(\n",
        "            xaxis=go.layout.XAxis(\n",
        "              title=go.layout.xaxis.Title(\n",
        "              text='n_estimators')\n",
        "             ),\n",
        "             yaxis=go.layout.YAxis(\n",
        "              title=go.layout.yaxis.Title(\n",
        "              text='max_features')\n",
        "            ) )\n",
        "    fig = go.Figure(data= [go.Surface(z=z, y=y, x=x)], layout=layout )\n",
        "    fig.update_layout(title='Hyperparameter tuning',\n",
        "                      scene = dict(\n",
        "                        xaxis_title='n_estimators',\n",
        "                        yaxis_title='max_features',\n",
        "                        zaxis_title='R2'),\n",
        "                      autosize=False,\n",
        "                      width=800, height=800,\n",
        "                      margin=dict(l=65, r=50, b=65, t=90))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    #-----Save grid data-----#\n",
        "    x = pd.DataFrame(x)\n",
        "    y = pd.DataFrame(y)\n",
        "    z = pd.DataFrame(z)\n",
        "    df = pd.concat([x,y,z], axis=1)\n",
        "    st.markdown(filedownload(grid_results), unsafe_allow_html=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghiP3TCdKAjm"
      },
      "source": [
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.write(df)\n",
        "    build_model(df)\n",
        "else:\n",
        "    st.info('Awaiting for CSV file to be uploaded.')\n",
        "    if st.button('Press to use Example Dataset'):\n",
        "        diabetes = load_diabetes()\n",
        "        X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "        Y = pd.Series(diabetes.target, name='response')\n",
        "        df = pd.concat( [X,Y], axis=1 )\n",
        "\n",
        "        st.markdown('The **Diabetes** dataset is used as the example.')\n",
        "        st.write(df.head(5))\n",
        "\n",
        "        build_model(df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}